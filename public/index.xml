<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Experi</title>
    <link>http://localhost:1313/</link>
    <description>Recent content on Experi</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 07 Jul 2015 19:52:26 +0200</lastBuildDate>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>What&#39;s on the stack?</title>
      <link>http://localhost:1313/unix02/</link>
      <pubDate>Tue, 07 Jul 2015 19:52:26 +0200</pubDate>
      
      <guid>http://localhost:1313/unix02/</guid>
      <description>

&lt;p&gt;This is the third post in my series on Grokking xv6. We will use GDB
to understanding how the stack works in detail. At the end of the post
there&amp;rsquo;s a video where we trace a system call from user space to kernel
space and back.&lt;/p&gt;

&lt;h2 id=&#34;introduction:6ae9618849cb95f299eb0577bfe82265&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;I want to begin with a word of warning. In this article there&amp;rsquo;ll be a
lot of things that you&amp;rsquo;ll see that we won&amp;rsquo;t explain. Instead, we are
going to learn how to squint at the code, suppress detail and focus on
what we want to do. There are a lot of guides out there that present a
fluffy view of reality, but I want to stay as faithful as possible to
what you would actually see using GDB and a real code base.&lt;/p&gt;

&lt;p&gt;One of the hardest parts so far
&lt;a href=&#34;http://experiments.oskarth.com/unix00/&#34;&gt;going through xv6&lt;/a&gt; was not having a
good mental model of the &lt;em&gt;stack&lt;/em&gt; and how it operates, I will attempt
to communicate at least a part of this to you.&lt;/p&gt;

&lt;h2 id=&#34;code:6ae9618849cb95f299eb0577bfe82265&#34;&gt;Code&lt;/h2&gt;

&lt;p&gt;We are going to look at some &lt;em&gt;assembly code&lt;/em&gt;. I do not expect you to
understand everything. Instead we will look at a few things and see
what they can teach us about the stack.&lt;/p&gt;

&lt;p&gt;When we type &lt;code&gt;ls&lt;/code&gt; in a terminal, the shell takes care of parsing the
input and then passes the control to the &lt;code&gt;ls&lt;/code&gt; program, &lt;code&gt;ls.c&lt;/code&gt;, which
is written in C. Here&amp;rsquo;s the &lt;em&gt;main function&lt;/em&gt; of that file:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;int
main(int argc, char *argv[])
{
  int i;

  if(argc &amp;lt; 2){
    ls(&amp;quot;.&amp;quot;);
    exit();
  }
  for(i=1; i&amp;lt;argc; i++)
    ls(argv[i]);
  exit();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is the main entry point of the &lt;code&gt;ls&lt;/code&gt; program. &lt;code&gt;argc&lt;/code&gt; stands for
&lt;em&gt;argument count&lt;/em&gt;, and if main doesn&amp;rsquo;t get a second argument (&lt;code&gt;ls&lt;/code&gt;
counts as the first argument to main) it will call the function &lt;code&gt;ls&lt;/code&gt;
with the argument &lt;code&gt;.&lt;/code&gt;. After that it will call the &lt;code&gt;exit&lt;/code&gt; function.&lt;/p&gt;

&lt;p&gt;We can get the assembly code for our main function with the
&lt;code&gt;disassemble&lt;/code&gt; command in &lt;em&gt;GDB&lt;/em&gt;. GDB is a debugger that allows us to
see what is going on inside a program when it executes. We will see a
lot of &amp;ldquo;code boxes&amp;rdquo; as we move on. Lines starting with &lt;code&gt;(gdb)&lt;/code&gt; are
lines that we write as input, and the other lines are things GDB shows
us.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(gdb) disassemble main
Dump of assembler code for function main:
=&amp;gt; 0x00000304 &amp;lt;+0&amp;gt;:     push   %ebp
0x00000305 &amp;lt;+1&amp;gt;:     mov    %esp,%ebp
0x00000307 &amp;lt;+3&amp;gt;:     and    $0xfffffff0,%esp
0x0000030a &amp;lt;+6&amp;gt;:     sub    $0x20,%esp
0x0000030d &amp;lt;+9&amp;gt;:     cmpl   $0x1,0x8(%ebp)
0x00000311 &amp;lt;+13&amp;gt;:    jg     0x324 &amp;lt;main+32&amp;gt;
0x00000313 &amp;lt;+15&amp;gt;:    movl   $0xb5f,(%esp)
0x0000031a &amp;lt;+22&amp;gt;:    call   0xb0 &amp;lt;ls&amp;gt;
0x0000031f &amp;lt;+27&amp;gt;:    call   0x5cb &amp;lt;exit&amp;gt;
0x00000324 &amp;lt;+32&amp;gt;:    movl   $0x1,0x1c(%esp)
0x0000032c &amp;lt;+40&amp;gt;:    jmp    0x34d &amp;lt;main+73&amp;gt;
0x0000032e &amp;lt;+42&amp;gt;:    mov    0x1c(%esp),%eax
0x00000332 &amp;lt;+46&amp;gt;:    lea    0x0(,%eax,4),%edx
0x00000339 &amp;lt;+53&amp;gt;:    mov    0xc(%ebp),%eax
0x0000033c &amp;lt;+56&amp;gt;:    add    %edx,%eax
0x0000033e &amp;lt;+58&amp;gt;:    mov    (%eax),%eax
0x00000340 &amp;lt;+60&amp;gt;:    mov    %eax,(%esp)
0x00000343 &amp;lt;+63&amp;gt;:    call   0xb0 &amp;lt;ls&amp;gt;
0x00000348 &amp;lt;+68&amp;gt;:    addl   $0x1,0x1c(%esp)
0x0000034d &amp;lt;+73&amp;gt;:    mov    0x1c(%esp),%eax
0x00000351 &amp;lt;+77&amp;gt;:    cmp    0x8(%ebp),%eax
0x00000354 &amp;lt;+80&amp;gt;:    jl     0x32e &amp;lt;main+42&amp;gt;
0x00000356 &amp;lt;+82&amp;gt;:    call   0x5cb &amp;lt;exit&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is a lot of code, and we are not going to understand all of it in
this post. Here&amp;rsquo;s how to read it. The first line is the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;=&amp;gt; 0x00000304 &amp;lt;+0&amp;gt;:     push   %ebp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;=&amp;gt;&lt;/code&gt; means that this is the instruction we are about to execute, but
haven&amp;rsquo;t yet. &lt;code&gt;0x00000304&lt;/code&gt; is the &lt;em&gt;address&lt;/em&gt; of the &lt;em&gt;instruction&lt;/em&gt;
written in &lt;em&gt;base 16&lt;/em&gt; or &lt;em&gt;hexadecimal&lt;/em&gt; or &lt;em&gt;hex&lt;/em&gt; - this is where the
instruction lives in memory. &lt;code&gt;&amp;lt;+0&amp;gt;&lt;/code&gt; is an offset that we are going to
ignore. &lt;code&gt;push&lt;/code&gt; is a &lt;em&gt;mnemonic&lt;/em&gt; or an &lt;em&gt;instruction&lt;/em&gt;, and its argument
in this case is &lt;code&gt;%ebp&lt;/code&gt;. We will talk more about instructions and what
their arguments mean in later sections.&lt;/p&gt;

&lt;p&gt;How does hexadecimal work? The &lt;em&gt;decimal&lt;/em&gt; alphabet consists of the
numbers 0 through 9, and the &lt;em&gt;binary&lt;/em&gt; alphabet consists of 0
and 1. Similarly, the hexadecimal alphabet has 16 &amp;ldquo;numbers&amp;rdquo; - 0
through 9 and then A through F. For example, 14 would be written
simply as &amp;ldquo;E&amp;rdquo;, and 17 as &amp;ldquo;11&amp;rdquo;. To differentiate between hexadecimal
numbers and decimal we use the &lt;em&gt;prefix&lt;/em&gt; &amp;ldquo;0x&amp;rdquo;, so 11 is 11 but &amp;ldquo;0x11&amp;rdquo;
is 17. &lt;em&gt;Addresses&lt;/em&gt; in the computer&amp;rsquo;s memory can be very long, so
instead of writing &lt;code&gt;0x00000304&lt;/code&gt; we can omit the leading zeroes and
write &lt;code&gt;0x304&lt;/code&gt; instead.&lt;/p&gt;

&lt;p&gt;Without knowing anything about assembly, you might notice that the
&lt;code&gt;call&lt;/code&gt; instruction occurs several times, and that its arguments is
either &lt;code&gt;&amp;lt;ls&amp;gt;&lt;/code&gt; or &lt;code&gt;&amp;lt;exit&amp;gt;&lt;/code&gt;. These &lt;code&gt;call&lt;/code&gt; instructions correspond to the
four function calls we see in our main function.&lt;/p&gt;

&lt;h2 id=&#34;the-stack:6ae9618849cb95f299eb0577bfe82265&#34;&gt;The Stack&lt;/h2&gt;

&lt;p&gt;If we follow the execution of a program by pointing at the screen we
might say &amp;ldquo;this calls this, which calls this, then it returns
here&amp;rdquo;. The stack is how the computer keeps track of things like this -
where it came from, what the arguments of a function are, etc.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s have a look at what&amp;rsquo;s on the stack before we have executed a
single instruction. We can do this using GDB&amp;rsquo;s &lt;code&gt;x&lt;/code&gt; command, which
allows us to inspect memory at a given address. It takes two
arguments: a format and an address.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(gdb) x /x $esp
0x2fe8: 0xffffffff
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In this case &lt;code&gt;/x&lt;/code&gt; is the format and &lt;code&gt;$esp&lt;/code&gt; is the address. We see that
$esp is set to &lt;code&gt;0x2fe8&lt;/code&gt; and the content of it is &lt;code&gt;0xffffffff&lt;/code&gt;. This is
what&amp;rsquo;s on top of the stack. We can see a bit more of what&amp;rsquo;s on the
stack with the following.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(gdb) x /4x $esp
0x2fe8: 0xffffffff      0x00000001      0x00002ff4      0x00002ffc
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here the format &lt;code&gt;/4x&lt;/code&gt; means &amp;ldquo;show me 4 &lt;em&gt;words&lt;/em&gt; in hex&amp;rdquo;. In GDB, a word
is 4 &lt;em&gt;bytes&lt;/em&gt; (and a byte is always 8 bits). Addresses are one word, or
32 bits, which is why it&amp;rsquo;s called a &lt;em&gt;32-bit architecture&lt;/em&gt;. &lt;em&gt;Registers&lt;/em&gt;
are also 32 bits.&lt;/p&gt;

&lt;p&gt;Registers store data for the &lt;em&gt;CPU&lt;/em&gt; for easy access. &lt;code&gt;esp&lt;/code&gt; is a special
&lt;em&gt;register&lt;/em&gt; called &lt;em&gt;(extended) stack pointer&lt;/em&gt;, and &lt;code&gt;$esp&lt;/code&gt; is the way
you reference it in GDB.&lt;/p&gt;

&lt;p&gt;At any given time, the stack pointer points to the top of the
stack. In the above output, &lt;code&gt;$esp&lt;/code&gt; is set to &lt;code&gt;0x2fe8&lt;/code&gt;, and it points
to &lt;code&gt;0xffffffff&lt;/code&gt;. We can also write the above in a slightly more
verbose way, for clarity. Each address on the left is offset by four
from the one above it.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0x2fe8: 0xffffffff &amp;lt;--- ESP
0x2fec: 0x00000001
0x2ff0: 0x00002ff4
0x2ff4: 0x00002ffc
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the abstract sense, a stack is a &lt;em&gt;LIFO&lt;/em&gt; (last in first out) data
structure that supports two primary operations: &lt;em&gt;push&lt;/em&gt; and &lt;em&gt;pop&lt;/em&gt;. It
is normally conceptualized as a stack of plates, growing upwards. What
might be confusing in this context is that the top of the stack has
the lowest address. The stack grows down, in terms of addresses, but
the last touched entry is still called the top of the stack. This
might be counterintuitive, but &amp;ldquo;top&amp;rdquo; is an abstract term and it
doesn&amp;rsquo;t become less of a stack because it&amp;rsquo;s growing down.&lt;/p&gt;

&lt;p&gt;Recall that the four lines above show what&amp;rsquo;s on the stack before we
have even executed a single instruction in our main function. What do
they mean? Before a function is called, its arguments are pushed onto
the stack, in reverse order, followed by the return address (also
known as as the return program counter or return PC). This way of
modifying the stack is part of a &lt;em&gt;calling convention&lt;/em&gt;. There are other
calling conventions, but this is the most common one for C.&lt;/p&gt;

&lt;p&gt;Our main function takes two arguments, argc and argv, whose values
are:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0x2fe8: 0xffffffff    &amp;lt;- -1, return address for main
0x2fec: 0x00000001    &amp;lt;- 1, argc value 
0x2ff0: 0x00002ff4    &amp;lt;- argv, pointer to argv[0]
0x2ff4: 0x00002ffc    &amp;lt;- &amp;quot;ls&amp;quot;, value of argv[0]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can cast &lt;code&gt;0x00002ffc&lt;/code&gt; to a &lt;code&gt;char*&lt;/code&gt; (a string) to see its human
readable representation. Likewise, we can do the same for main&amp;rsquo;s
return address, &lt;code&gt;0xffffffff&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(gdb) print (char*)0x00002ffc
$83 = 0x2ffc &amp;quot;ls&amp;quot;
(gdb) print (int)0xffffffff
$88 = -1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;main&lt;/code&gt; has a fake return address. Since it has no place to return to,
it is simply set to -1.&lt;/p&gt;

&lt;h2 id=&#34;one-instruction-at-a-time:6ae9618849cb95f299eb0577bfe82265&#34;&gt;One instruction at a time&lt;/h2&gt;

&lt;p&gt;We are now going to step through the beginning of the program,
instruction by instruction. We can see the first four instructions to
be executed:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(gdb) x /4i $eip
=&amp;gt; 0x304 &amp;lt;main&amp;gt;:        push   %ebp
   0x305 &amp;lt;main+1&amp;gt;:      mov    %esp,%ebp
   0x307 &amp;lt;main+3&amp;gt;:      and    $0xfffffff0,%esp
   0x30a &amp;lt;main+6&amp;gt;:      sub    $0x20,%esp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We use the &lt;code&gt;/4i&lt;/code&gt; format to interpret the content of the four
addresses, starting at &lt;code&gt;$eip&lt;/code&gt;, as instructions. There are no
guardrails here - GDB doesn&amp;rsquo;t care if you read memory that represents,
say, a number as an instruction.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$eip&lt;/code&gt; is a register that&amp;rsquo;s called an &lt;em&gt;(extended) instruction
pointer&lt;/em&gt;. This points to the next instruction we are about to
execute. These four instructions are called the &lt;em&gt;function
prologue&lt;/em&gt;. What does the stack look like after we perform these
instructions?&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s do it one by one using GDB&amp;rsquo;s &lt;code&gt;stepi&lt;/code&gt; function. After &lt;code&gt;push %ebp&lt;/code&gt;
this is the stack:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0x2fe4: 0x00003fb8  &amp;lt;--- ESP
0x2fe8: 0xffffffff
0x2fec: 0x00000001
0x2ff0: 0x00002ff4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Two things have happened: we have moved the stack pointer up an
address, and put a new value there. The push instruction does both of
those things one after another. This is slightly tricky as there&amp;rsquo;s no
mention of &lt;code&gt;$esp&lt;/code&gt; in that instruction, but yet it changed our stack
pointer. There are only a few instructions like these though: &lt;code&gt;push&lt;/code&gt;,
&lt;code&gt;pop&lt;/code&gt;, &lt;code&gt;call&lt;/code&gt;, &lt;code&gt;ret&lt;/code&gt; and a few others. Another way to write &lt;code&gt;push
$ebp&lt;/code&gt; is as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sub $0x4 $esp
mov $ebp ($esp)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This subtracts 4 from the stack pointer and puts &lt;code&gt;$ebp&lt;/code&gt; in whatever
the stack pointer is pointing to. &lt;code&gt;$esp&lt;/code&gt; is the address of the stack
pointer, and &lt;code&gt;($esp)&lt;/code&gt; is what the stack pointer points to (just like
with pointers in C):&lt;/p&gt;

&lt;p&gt;What is &lt;code&gt;$ebp&lt;/code&gt;? It stands for &lt;em&gt;(extended) base pointer&lt;/em&gt; (or sometimes
it&amp;rsquo;s called a frame pointer, depending on the architecture). The idea
is that the stack pointer changes throughout the function as variables
and registers are pushed and popped, but the base pointer stays the
same throughout. That means that we can use the base pointer as an
anchor to find parameters and local variables. For example, if you
look at the first assembly code listing, you can see that there are
things like &lt;code&gt;0x8(%ebp)&lt;/code&gt;. This takes the content of &lt;code&gt;%ebp&lt;/code&gt; but offset
by 8, which is two words, and in this case that&amp;rsquo;s where argc is
located.&lt;/p&gt;

&lt;p&gt;The next instruction after the &lt;code&gt;push&lt;/code&gt; instruction is &lt;code&gt;mov %esp, %ebp&lt;/code&gt;
nothing changes on the stack. This moves our stack pointer into the
&lt;em&gt;base pointer&lt;/em&gt; address.&lt;/p&gt;

&lt;p&gt;The third instruction is &lt;code&gt;and $0xfffffff0,%esp&lt;/code&gt;, and it&amp;rsquo;s a so called
stack alignment (&lt;code&gt;0xfffffff0&lt;/code&gt; is -16 in hex, using two&amp;rsquo;s
complement). It ensures that the stack pointer will be at its current
position in memory, or at a lower one, but more importantly that it
will be at a 16-byte boundary. Why this is done is outside of the
scope of this article, but it has to do with performance and being
able to do several instructions in parallel on certain architectures
with something called &lt;em&gt;SIMD&lt;/em&gt;. We can see that the stack pointer is
evenly divided by 16 with &lt;code&gt;print 0x2fe0 % 16&lt;/code&gt; (or just by looking at
the last position in the hex number, since that&amp;rsquo;s the &amp;ldquo;16&amp;rdquo;-th
position). This is what the stack looks like now:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0x2fe0: 0x00000000  &amp;lt;--- ESP
0x2fe4: 0x00003fb8
0x2fe8: 0xffffffff
0x2fec: 0x00000001
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After &lt;code&gt;sub $0x20,%esp&lt;/code&gt;, which subtracts &lt;code&gt;0x20&lt;/code&gt; (2 times 16 is 32 in
decimal) from our stack pointer, we&amp;rsquo;ve made room for 32 bytes on the
stack. This is used for local variables in main.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(gdb) x /12x $esp
0x2fc0: 0x00000000      0x00000000      0x00000000      0x00000000
0x2fd0: 0x00000000      0x00000000      0x00000000      0x00000000
0x2fe0: 0x00000000      0x00003fb8      0xffffffff      0x00000001
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We will show the stack using the more concise format from now on.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ve now performed four instructions in main and this is the end of
the &lt;em&gt;function prologue&lt;/em&gt;. Something similar to this is done in every
function. There&amp;rsquo;s also an &lt;em&gt;function epilogue&lt;/em&gt; - and of course the main
meat of the function in between.&lt;/p&gt;

&lt;h2 id=&#34;calling-ls:6ae9618849cb95f299eb0577bfe82265&#34;&gt;Calling ls&lt;/h2&gt;

&lt;p&gt;If we step two more instructions (&lt;code&gt;stepi 2&lt;/code&gt;) we get to:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;movl   $0xb5f,(%esp)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;which puts 0xb5f on the stack without changing the stack pointer (good
thing we made room for local variables before so we didn&amp;rsquo;t overwrite
our stack!) What is that? Just like was done to &lt;code&gt;main&lt;/code&gt; in the very
beginning, before we call &lt;code&gt;ls&lt;/code&gt; (the function, not the program -
henceforth we will just talk about the function &lt;code&gt;ls&lt;/code&gt; inside the &lt;code&gt;ls&lt;/code&gt;
program) we push the argument on the stack. We know there&amp;rsquo;s only one
argument and that it should be a string, and we can see the true
nature of it by casting it to a char*:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print (char*)0xb5f
$2 = 0xb5f &amp;quot;.&amp;quot;
(gdb) x /4x $esp
0x2fc0: 0x00000b5f      0x00000000      0x00000000      0x00000000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The next instruction is &lt;code&gt;call 0xb0 &amp;lt;ls&amp;gt;&lt;/code&gt;. &lt;code&gt;call&lt;/code&gt; does two things, it
pushes the address of the next instruction in &lt;code&gt;main&lt;/code&gt; onto the stack,
and then it &lt;em&gt;jumps&lt;/em&gt; to a subprogram (which is just another address in
memory, but since our program was compiled with debug information on
we can see that it says &lt;code&gt;&amp;lt;ls&amp;gt;&lt;/code&gt;). A jump changes the instruction
pointer to its argument. After executing that instruction our stack
and our upcoming four instructions to execute looks like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(gdb) x /4x $esp
0x2fbc: 0x0000031f      0x00000b5f      0x00000000      0x00000000
(gdb) x /4i $eip
=&amp;gt; 0xb0 &amp;lt;ls&amp;gt;:   push   %ebp
   0xb1 &amp;lt;ls+1&amp;gt;: mov    %esp,%ebp
   0xb3 &amp;lt;ls+3&amp;gt;: push   %edi
   0xb4 &amp;lt;ls+4&amp;gt;: push   %esi
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We are now in the &lt;code&gt;ls&lt;/code&gt; function, and &lt;code&gt;0xb0&lt;/code&gt;, which was an argument to
call, is what our instruction pointer is set to. You might recognize
the two first lines from the prologue in our main function.&lt;/p&gt;

&lt;p&gt;What about &lt;code&gt;0x0000031f&lt;/code&gt; that is now on top of our stack? It&amp;rsquo;s the
address where the program should keep executing once the ls function
returns. We can confirm this by looking at it&amp;rsquo;s memory location as
instructions. These are exactly the instructions that come after the
call to ls (see the code section above).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(gdb) x /4i 0x0000031f
   0x31f &amp;lt;main+27&amp;gt;:     call   0x5cb &amp;lt;exit&amp;gt;
   0x324 &amp;lt;main+32&amp;gt;:     movl   $0x1,0x1c(%esp)
   0x32c &amp;lt;main+40&amp;gt;:     jmp    0x34d &amp;lt;main+73&amp;gt;
   0x32e &amp;lt;main+42&amp;gt;:     mov    0x1c(%esp),%eax
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We are still in ls though. Let&amp;rsquo;s step two more instructions, pushing
the base pointer onto the stack and moving (or &amp;ldquo;saving&amp;rdquo;) the stack
pointer to the base pointer.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(gdb) x /4x $esp
0x2fb8: 0x00002fe4      0x0000031f      0x00000b5f      0x00000000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The new address on the stack is our old base pointer from main. We&amp;rsquo;ve
seen this before, but let&amp;rsquo;s take a look again.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(gdb) x /4x 0x00002fe4
0x2fe4: 0x00003fb8      0xffffffff      0x00000001      0x00002ff4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is exactly our stack at the beginning of main, so we now have
easy access to that state for when we want to go back to it.&lt;/p&gt;

&lt;h2 id=&#34;skipping-until-the-end-of-ls:6ae9618849cb95f299eb0577bfe82265&#34;&gt;Skipping until the end of ls&lt;/h2&gt;

&lt;p&gt;There&amp;rsquo;s a lot that happens in &lt;code&gt;ls&lt;/code&gt; and the functions it calls. We are
going to skip all that by going to the very last line of the C code in
the ls function
(&lt;a href=&#34;https://github.com/oskarth/xv6/blob/master/ls.c&#34;&gt;code&lt;/a&gt;), line 71. We
do this with the GDB command &lt;code&gt;until 71&lt;/code&gt;. When we are at the end of
&lt;code&gt;ls&lt;/code&gt;, what&amp;rsquo;s about to happen now and what does the stack look like?&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(gdb) x /6i $eip
=&amp;gt; 0x2f9 &amp;lt;ls+585&amp;gt;:      add    $0x25c,%esp
   0x2ff &amp;lt;ls+591&amp;gt;:      pop    %ebx
   0x300 &amp;lt;ls+592&amp;gt;:      pop    %esi
   0x301 &amp;lt;ls+593&amp;gt;:      pop    %edi
   0x302 &amp;lt;ls+594&amp;gt;:      pop    %ebp
   0x303 &amp;lt;ls+595&amp;gt;:      ret
(gdb) x /4x $esp
0x2d50: 0x00000003      0x00002d88      0x00000010      0x00000001
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We don&amp;rsquo;t know what those things on the stack are, but presumably they
come from something ls did - in fact, we would have to run &lt;code&gt;x /170x
$esp&lt;/code&gt; to begin to see addresses that we recognize on our stack. That&amp;rsquo;s
okay though, we are about the clean that stack up with the function
epilogue. Essentially the five first instructions are the opposite of
subtracting and pushing things onto the stack. If we step through them
with &lt;code&gt;stepi 5&lt;/code&gt; we get:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(gdb) x /4x $esp
0x2fbc: 0x0000031f      0x00000b5f      0x00000000      0x00000000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Before we did that our stack pointer was set to &lt;code&gt;0x2d50&lt;/code&gt;, and now it&amp;rsquo;s
back to &lt;code&gt;0x2fbc&lt;/code&gt;. As a sanity check on what&amp;rsquo;s going on, we can see
that everything seems OK: we just cleaned up 620 bytes, of which the
first &lt;code&gt;add $0x25c, %esp&lt;/code&gt; took care of 604. &lt;code&gt;pop&lt;/code&gt; was called four
times, and 4 times 4 bytes (the size of each register that we popped)
is 16, which takes care of the rest.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print  0x2fbc - 0x2d50
$3 = 620
print 0x25c
$4 = 604
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Our stack pointer is now back at &lt;code&gt;0x2fbc&lt;/code&gt;, which is where it was at
the very beginning of the &lt;code&gt;ls&lt;/code&gt; function. The next instruction is a
simple &lt;code&gt;ret&lt;/code&gt;. What does &lt;code&gt;ret&lt;/code&gt; do? It&amp;rsquo;s the opposite of &lt;code&gt;call&lt;/code&gt;: it pops
off an address, and jumps to it. So without single stepping, we should
expect it to jump to &lt;code&gt;0x31f&lt;/code&gt; and set the stack pointer to &lt;code&gt;0x2fbc + 4&lt;/code&gt;
= &lt;code&gt;0x2fc0&lt;/code&gt;. What is &lt;code&gt;0x31f&lt;/code&gt; again? It&amp;rsquo;s the next line in &lt;code&gt;main&lt;/code&gt; after
calling &lt;code&gt;ls&lt;/code&gt;. After single stepping it:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x /4x $esp
0x2fc0: 0x00000b5f      0x00000000      0x00000000      0x00000000
x /4i $eip
=&amp;gt; 0x31f &amp;lt;main+27&amp;gt;:     call   0x5cb &amp;lt;exit&amp;gt;
   0x324 &amp;lt;main+32&amp;gt;:     movl   $0x1,0x1c(%esp)
   0x32c &amp;lt;main+40&amp;gt;:     jmp    0x34d &amp;lt;main+73&amp;gt;
   0x32e &amp;lt;main+42&amp;gt;:     mov    0x1c(%esp),%eax
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Indeed, we are now back in &lt;code&gt;main&lt;/code&gt; and are about to call &lt;code&gt;exit&lt;/code&gt;, and
our stack is back to the same state it was just before it was about to
call &lt;code&gt;ls&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&#34;stack-traces:6ae9618849cb95f299eb0577bfe82265&#34;&gt;Stack traces&lt;/h2&gt;

&lt;p&gt;When you program in a high-level language you might come across &lt;em&gt;stack
traces&lt;/em&gt; that show who called a function and with which arguments. GDB
also has support for this, and if we were executing in the middle of
the &lt;code&gt;ls&lt;/code&gt; function we could see the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(gdb) info stack
#0  ls (path=path@entry=0xb5f &amp;quot;.&amp;quot;) at ls.c:33
#1  0x0000031f in main (argc=1, argv=0x2ff4) at ls.c:79
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here we have two &lt;em&gt;stack frames&lt;/em&gt;. A stack frame is created at every
function invocation and contains arguments to the function, its return
address, and space for local variables.&lt;/p&gt;

&lt;p&gt;In this case we are in stack frame #0 (the inner frame), executing
instructions in &lt;code&gt;ls&lt;/code&gt;, and we came from main. Notice that the base
pointer we talked about earlier, &lt;code&gt;0x31f&lt;/code&gt;, is there as the start of the
other stack frame (the outer frame).&lt;/p&gt;

&lt;p&gt;You can see a stack trace just shows you all the stack frames, which
we have meticulously (our rather, our compile has) constructed at the
lower level. There&amp;rsquo;s no magic.&lt;/p&gt;

&lt;h2 id=&#34;conclusion-and-demo:6ae9618849cb95f299eb0577bfe82265&#34;&gt;Conclusion and demo&lt;/h2&gt;

&lt;p&gt;We started off looking at a simple piece of C code and its equivalent
assembly code. We then inspected the stack before a single instruction
had been executed, and we then carefully went through the first few
instructions in that function to see how the stack frame was set
up. Then we saw how another function, ls, was called and how that
changed the stack, preserving the stack state of the calling
function. We then skipped a whole bunch of code only to catch our
stack being cleaned up, and finally getting returned to the main
function again with its stack frame intact.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s the video that was promised. In it we trace a system call from
user space to kernel space and back.&lt;/p&gt;

&lt;div style = &#34;text-align:center&#34;&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/TWksEdn5eoA&#34; frameborder=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>What is a shell and how does it work?</title>
      <link>http://localhost:1313/unix01/</link>
      <pubDate>Fri, 26 Jun 2015 19:00:00 +0200</pubDate>
      
      <guid>http://localhost:1313/unix01/</guid>
      <description>

&lt;p&gt;This post is part of my ongoing experiment in grokking xv6. In it I will teach
you what a shell is and how it works.&lt;/p&gt;

&lt;p&gt;If you haven&amp;rsquo;t read first part in this series, you can read it
&lt;a href=&#34;http://experiments.oskarth.com/unix00/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In my experience, most technical explanations are full of jargon and implicit
knowledge. Throughout the text I&amp;rsquo;ve deliberately italicized the first use of all
terms that can be seen as domain-specific. In cases where I think an elaboration
seems necessary, I&amp;rsquo;ve included either a short in-line explanation or a footnote.
Does this type of explanation - being explicit about the words you use - help
with understanding, or is the italicization just getting in the way of reading?&lt;/p&gt;

&lt;p&gt;In general, any explanation that is clear and concise is good. This type of
explanation tries to err more on the side of clarity, rather than conciseness. &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:f09b8128b2cd6dc70217eeb5f2ae4fb1:1&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:f09b8128b2cd6dc70217eeb5f2ae4fb1:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;h2 id=&#34;what-is-a-shell:f09b8128b2cd6dc70217eeb5f2ae4fb1&#34;&gt;What is a shell?&lt;/h2&gt;

&lt;p&gt;A &lt;em&gt;shell&lt;/em&gt; is just another &lt;em&gt;computer program&lt;/em&gt;. It is the main &lt;em&gt;user interface&lt;/em&gt; to
&lt;em&gt;operating systems&lt;/em&gt; that are similar to &lt;em&gt;Unix&lt;/em&gt;. An operating system is
responsible for having several programs run on one &lt;em&gt;computer&lt;/em&gt;, and also to tries
to &lt;em&gt;abstract away&lt;/em&gt; the specific &lt;em&gt;hardware&lt;/em&gt; the computer is running on, so the
same program can run on many different types of computers. Unix is a special
type of operating system that was developed at &lt;em&gt;Bell Labs&lt;/em&gt; by &lt;em&gt;programmers&lt;/em&gt; like
&lt;em&gt;Ken Thompson&lt;/em&gt;, &lt;em&gt;Dennis Ritchie&lt;/em&gt;, and &lt;em&gt;Brian Kernighan&lt;/em&gt;. A &lt;em&gt;kernel&lt;/em&gt; is the part
of the operating system that we will be concerned with. Modern operating systems
also provide things like &lt;em&gt;graphical interfaces&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;The shell lives in &lt;em&gt;user space&lt;/em&gt;, along with most other programs, as opposed to
in &lt;em&gt;kernel space&lt;/em&gt; which is where the kernel lives. &lt;em&gt;Software&lt;/em&gt; living in kernel
space can execute &lt;em&gt;privileged instructions&lt;/em&gt;, such as dealing directly with
hardware. We don’t want any software to be able to do this, as it could
&lt;em&gt;overwrite&lt;/em&gt; the operating system itself. The way the shell talks to the kernel
is by system calls &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:f09b8128b2cd6dc70217eeb5f2ae4fb1:2&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:f09b8128b2cd6dc70217eeb5f2ae4fb1:2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. These system calls allows the user to do things like
&lt;em&gt;open files&lt;/em&gt; and &lt;em&gt;create processes&lt;/em&gt;. Since software in user space always have to
go through the kernel to perform such operations, the kernel can make sure the
shell doesn&amp;rsquo;t do anything it doesn&amp;rsquo;t want to allow. Note that this is different
from a &lt;em&gt;super-user&lt;/em&gt; or &lt;em&gt;running as root&lt;/em&gt;, which is about &lt;em&gt;user privilege&lt;/em&gt; that
software in user space have.&lt;/p&gt;

&lt;h2 id=&#34;hello-shell:f09b8128b2cd6dc70217eeb5f2ae4fb1&#34;&gt;Hello shell&lt;/h2&gt;

&lt;p&gt;If you want to see a list of what&amp;rsquo;s inside the &lt;em&gt;directory&lt;/em&gt; in your &lt;em&gt;present
working directory&lt;/em&gt; &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:f09b8128b2cd6dc70217eeb5f2ae4fb1:3&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:f09b8128b2cd6dc70217eeb5f2ae4fb1:3&#34;&gt;3&lt;/a&gt;&lt;/sup&gt; you can use the program &lt;em&gt;ls&lt;/em&gt;. Typing &lt;code&gt;ls&lt;/code&gt; in a shell and
pressing enter runs it and returns the contents of that folder. When you press
enter the shell first &lt;em&gt;parses&lt;/em&gt; &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:f09b8128b2cd6dc70217eeb5f2ae4fb1:4&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:f09b8128b2cd6dc70217eeb5f2ae4fb1:4&#34;&gt;4&lt;/a&gt;&lt;/sup&gt; what you wrote into some internal
representation. What does it mean to run &lt;code&gt;ls&lt;/code&gt;? To answer that we must first
understand what the &lt;em&gt;fork&lt;/em&gt; system call does and what a &lt;em&gt;child process&lt;/em&gt; is.&lt;/p&gt;

&lt;p&gt;Recall that an operating systems allows several programs to run on one computer,
and processes are a big part of how it does that. A &lt;em&gt;process&lt;/em&gt; in Unix-like
systems is a program that runs and has access to its own piece of &lt;em&gt;memory&lt;/em&gt; which
contains the program&amp;rsquo;s &lt;em&gt;instructions&lt;/em&gt;, &lt;em&gt;data&lt;/em&gt; and &lt;em&gt;stack&lt;/em&gt;. The operating system
then makes sure each process gets to do what it wants to do in some reasonable
manner. Fork is a system call that allows a process to create another process.
The process &lt;em&gt;calling&lt;/em&gt; fork is called the parent process, and the process it
creates is called the child process. When a child process starts, its memory is
initally almost an exact, but separate, copy of its parent process&amp;rsquo;s memory.&lt;/p&gt;

&lt;p&gt;In the case of our &lt;code&gt;ls&lt;/code&gt; command, the shell runs the parsed command in a forked
child process. In &lt;em&gt;C&lt;/em&gt; &lt;em&gt;code&lt;/em&gt; it would look something like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;int pid = fork();
if(pid == 0)
  runcmd(parsecmd(buf));
wait();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When we call fork we create a child process, and we get back an integer that we
call &lt;em&gt;pid&lt;/em&gt; for process id. We now have two different processes running
independently, and the &lt;em&gt;variable&lt;/em&gt; pid is different in the two. In the parent
process, the pid is some number that is used to uniquely identify the process,
whereas in the child process it&amp;rsquo;s simply equal to 0.&lt;/p&gt;

&lt;p&gt;A good way to think about the above piece of code is to see it as being two
different programs. In the parent process, the &lt;em&gt;if-statement&lt;/em&gt; returns false and
it gets stuck at &lt;em&gt;wait&lt;/em&gt;, which is another system call that just waits until a
child process is finished. The kernel makes sure the parent is notified when
that happens. In the child process, the if-statement returns true and it runs
the command. This executes &lt;code&gt;ls&lt;/code&gt; and gives over all control to &lt;code&gt;ls&lt;/code&gt; for that
process.&lt;/p&gt;

&lt;p&gt;Once the child process has finished running - and when that happens is
completely up to &lt;code&gt;ls&lt;/code&gt; and how it is implemented - the parent process, i.e. the
shell, will resume running, and we can type another command.&lt;/p&gt;

&lt;h2 id=&#34;i-o-redirection:f09b8128b2cd6dc70217eeb5f2ae4fb1&#34;&gt;I/O Redirection&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s say we want to save the &lt;em&gt;output&lt;/em&gt; from running &lt;code&gt;ls&lt;/code&gt; above. We can do so
using something called &lt;em&gt;I/O redirection&lt;/em&gt; (I/O stands for &lt;em&gt;input/output&lt;/em&gt;):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ls &amp;gt; foo
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There are three parts to this command. When the shell parses the command, it
figures out that it&amp;rsquo;s a redirection from &lt;code&gt;ls&lt;/code&gt; to &lt;code&gt;foo&lt;/code&gt;. After the shell has
forked to a child process it runs &lt;code&gt;ls&lt;/code&gt; and saves the output in a &lt;em&gt;file&lt;/em&gt; called
foo. An ordinary file contains either &lt;em&gt;symbolic&lt;/em&gt; or &lt;em&gt;binary&lt;/em&gt; data, is written in
some &lt;em&gt;format&lt;/em&gt;, and has some &lt;em&gt;metadata&lt;/em&gt; associated with it (such as who is
allowed to read and write to it), and we can access it by using its &lt;em&gt;pathname&lt;/em&gt;.
One of the most common type of file is a &lt;em&gt;text file&lt;/em&gt;, which contains a &lt;em&gt;string&lt;/em&gt;
of &lt;em&gt;characters&lt;/em&gt;. There are special files too, and in fact even &lt;em&gt;devices&lt;/em&gt; and
&lt;em&gt;directories&lt;/em&gt; are represented as files.&lt;/p&gt;

&lt;p&gt;How does the output of ls end up in foo? To understand that we have to know a
bit more about files work in Unix. The system call &lt;em&gt;open&lt;/em&gt; is used to see the
contents of a file. When we open a file to read or write to it, we get a &lt;em&gt;file
descriptor&lt;/em&gt; back. This file descriptor is just an &lt;em&gt;integer&lt;/em&gt; that represents a
specific file that a process can read or write to. There are three special
integers, 0, 1, and 2. These are called, in order, &lt;em&gt;STDIN&lt;/em&gt; (standard input),
&lt;em&gt;STDOUT&lt;/em&gt; (standard output), and &lt;em&gt;STDERR&lt;/em&gt; (standard error). Another word for
these is &lt;em&gt;standard streams&lt;/em&gt;. By default, when the shell reads something, such as
a command you typed in, it does this from STDIN. Likewise, when the shell prints
something, such as the result of running some command, it does this to STDOUT.&lt;/p&gt;

&lt;p&gt;There is some confusion about the difference between files and streams, and
people can mean different things when they talk about them. For our present
purposes, we can treat them as equivalent - as long we let go of our
preconceptions of what a file is. As alluded to before, many things are seen as
as files from the kernel&amp;rsquo;s point of view in Unix-like systems.&lt;/p&gt;

&lt;p&gt;When we run &lt;code&gt;ls&lt;/code&gt;, it returns the result by &lt;em&gt;printing&lt;/em&gt; it &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:f09b8128b2cd6dc70217eeb5f2ae4fb1:5&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:f09b8128b2cd6dc70217eeb5f2ae4fb1:5&#34;&gt;5&lt;/a&gt;&lt;/sup&gt; to STDOUT, and
STDOUT is what we see in the shell. File descriptors are handed out by the
kernel starting from the lowest available file descriptor, and when the shell
starts it opens the three standard streams. We can use this fact to get I/O
redirection with something like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;close(fd);
open(file, mode);
runcmd(cmd);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is a simplified version of the actual code and it has no error handling.
The second &lt;em&gt;argument&lt;/em&gt; to open is mode, which is where we say if we want to read
or write to the file. Assuming we want to redirect using &lt;code&gt;&amp;gt;&lt;/code&gt;, we close STDOUT.
When we then open the file, foo in this case, to write to it, it will pick the
lowest available file descriptor, which is 1. When we then run the command &lt;code&gt;ls&lt;/code&gt;,
it will print to STDOUT - which is &lt;em&gt;bound&lt;/em&gt; to our file foo.&lt;/p&gt;

&lt;h2 id=&#34;pipes:f09b8128b2cd6dc70217eeb5f2ae4fb1&#34;&gt;Pipes&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s look at another example. There&amp;rsquo;s a program called &lt;em&gt;ps&lt;/em&gt; that shows the
&lt;em&gt;status&lt;/em&gt; of processes. If we want to have a list of all my processes sorted by
their process id we can &lt;em&gt;pipe&lt;/em&gt; the result of running ps to the program &lt;em&gt;sort&lt;/em&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ps | sort
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When the shell parses this command it sees the symbol &amp;ldquo;|&amp;rdquo; and knows it&amp;rsquo;s a pipe
command. A pipe command has two sides: a left and a right side. When we write on
the left side we can read from right side. A pipe is a small &lt;em&gt;buffer&lt;/em&gt; &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:f09b8128b2cd6dc70217eeb5f2ae4fb1:6&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:f09b8128b2cd6dc70217eeb5f2ae4fb1:6&#34;&gt;6&lt;/a&gt;&lt;/sup&gt; that
lives in kernel space and allows processes to talk to each other, which is
called &lt;em&gt;inter-process communication&lt;/em&gt;. This communication happens continuously as
new data is written to the pipe. It&amp;rsquo;s also a &lt;em&gt;queue&lt;/em&gt;, so even if new data comes
in faster than you can process it in the right process the data doesn&amp;rsquo;t
disappear, and it doesn&amp;rsquo;t &lt;em&gt;block&lt;/em&gt; &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:f09b8128b2cd6dc70217eeb5f2ae4fb1:7&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:f09b8128b2cd6dc70217eeb5f2ae4fb1:7&#34;&gt;7&lt;/a&gt;&lt;/sup&gt; either.&lt;/p&gt;

&lt;p&gt;How does this work? Let&amp;rsquo;s look at the code.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;int p[2];
pipe(p);

if(fork() == 0) {
  close(1);
  dup(p[1]);
  close(p[0]);
  close(p[1]);
  runcmd(left);
}
if(fork() == 0) {
  close(0);
  dup(p[0]);
  close(p[0]);
  close(p[1]);
  runcmd(right);
}
close(p[0]);
close(p[1]);
wait();
wait();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We create an array of two integers, which is where we will keep track of our
file descriptors. We then use the system call pipe, which creates a pipe between
two file descriptors and and puts these in p, where p[0] is for reading and
p[1] is for writing. After that, we create two child processes - one for the
left process and one for the right one. These are the two if-blocks that check
if fork returns 0, which it does in the child processes.&lt;/p&gt;

&lt;p&gt;In the left process we close STDOUT. Then we use another system call &lt;em&gt;dup&lt;/em&gt; that
duplicates a file descriptor. What this means is that we can refer to the same
file or stream but using a different file descriptor. Since STDOUT is closed
and it&amp;rsquo;s the lowest available file descriptor, the write-end of our pipe gets
connected to STDOUT in this process.&lt;/p&gt;

&lt;p&gt;Recall that a child process has almost exactly the same memory as a parent
process. This includes file descriptors, so after we have connected the left
process to STDOUT we want to close the file descriptors in p. If we don&amp;rsquo;t, we
might get a &lt;em&gt;deadlock&lt;/em&gt; where we don&amp;rsquo;t ever see anything printed. For example, if
we forget to close the write-end of the pipe (p[1]) in the right child process,
the read-end of the pipe (p[0]) will keep waiting for data. This means that the
left child process won&amp;rsquo;t ever finish, and the the parent process will wait
forever. It&amp;rsquo;s only when the write-end of a pipe is closed that the read-end
stops waiting. This is similar to how ordinary files have a specific
&lt;em&gt;end-of-file&lt;/em&gt; character that tells us when a file is finished.&lt;/p&gt;

&lt;p&gt;Depending on the exact command, things might still work out fine even if you
forget to close a file descriptor. However, in order to avoid subtle bugs,
consider it good hygiene to close a file descriptor when you are done with it.&lt;/p&gt;

&lt;p&gt;After all that, we run the left process and it prints to STDOUT. Similarly, the
right process does almost the exact same thing but for STDIN. And finally, the
parent closes the file descriptors for the pipe and waits for both child
processes to finish (which, if it&amp;rsquo;s a &lt;em&gt;long-running process&lt;/em&gt;, may never
happen).&lt;/p&gt;

&lt;h2 id=&#34;conclusion:f09b8128b2cd6dc70217eeb5f2ae4fb1&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;In this article we&amp;rsquo;ve looked at how the shell executes a simple command, how I/O
redirection works, and how pipes allow for inter-process comunication. We&amp;rsquo;ve
also looked briefly at what files and process are, and how to use some basic
system calls.&lt;/p&gt;

&lt;p&gt;I hope I have managed to paint a clear picture of the shell. If you wish to
solidify your understanding of the shell, I recommend you to do what I did and
go through the xv6 shell in detail, and perhaps do some of the suggested
homework in MIT&amp;rsquo;s operating systems class. If you have any comments, please
don&amp;rsquo;t hesitate to &lt;a href=&#34;mailto:me@oskarth.com&#34;&gt;email&lt;/a&gt; or
&lt;a href=&#34;https://twitter.com/oskarth&#34;&gt;tweet&lt;/a&gt; me.&lt;/p&gt;

&lt;h2 id=&#34;resources:f09b8128b2cd6dc70217eeb5f2ae4fb1&#34;&gt;Resources&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;xv6 shell code: &lt;a href=&#34;https://github.com/oskarth/xv6/blob/master/homework/sh.c&#34;&gt;https://github.com/oskarth/xv6/blob/master/homework/sh.c&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;MIT&amp;rsquo;s OS class: &lt;a href=&#34;http://pdos.csail.mit.edu/6.828/2014/&#34;&gt;http://pdos.csail.mit.edu/6.828/2014/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;xv6 book: &lt;a href=&#34;http://pdos.csail.mit.edu/6.828/2014/xv6/book-rev8.pdf&#34;&gt;http://pdos.csail.mit.edu/6.828/2014/xv6/book-rev8.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;xv6 code: &lt;a href=&#34;http://pdos.csail.mit.edu/6.828/2014/xv6/xv6-rev8.pdf&#34;&gt;http://pdos.csail.mit.edu/6.828/2014/xv6/xv6-rev8.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Unix paper: &lt;a href=&#34;http://www.cs.berkeley.edu/~brewer/cs262/unix.pdf&#34;&gt;http://www.cs.berkeley.edu/~brewer/cs262/unix.pdf&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:f09b8128b2cd6dc70217eeb5f2ae4fb1:1&#34;&gt;But conciseness is still more important than completeness.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:f09b8128b2cd6dc70217eeb5f2ae4fb1:1&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:f09b8128b2cd6dc70217eeb5f2ae4fb1:2&#34;&gt;&lt;em&gt;System calls&lt;/em&gt;: Things you can tell the kernel to do in kernel space.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:f09b8128b2cd6dc70217eeb5f2ae4fb1:2&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:f09b8128b2cd6dc70217eeb5f2ae4fb1:3&#34;&gt;&lt;em&gt;Present working directory&lt;/em&gt;: Where you are in the &lt;em&gt;file hierarchy&lt;/em&gt; at any given time.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:f09b8128b2cd6dc70217eeb5f2ae4fb1:3&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:f09b8128b2cd6dc70217eeb5f2ae4fb1:4&#34;&gt;&lt;em&gt;Parsing&lt;/em&gt;: Figures out the parts of what you told it are.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:f09b8128b2cd6dc70217eeb5f2ae4fb1:4&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:f09b8128b2cd6dc70217eeb5f2ae4fb1:5&#34;&gt;&lt;em&gt;Printing&lt;/em&gt;: Writing it in a place where you can see it.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:f09b8128b2cd6dc70217eeb5f2ae4fb1:5&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:f09b8128b2cd6dc70217eeb5f2ae4fb1:6&#34;&gt;&lt;em&gt;Buffer&lt;/em&gt;: A place where temporary data is stored.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:f09b8128b2cd6dc70217eeb5f2ae4fb1:6&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:f09b8128b2cd6dc70217eeb5f2ae4fb1:7&#34;&gt;&lt;em&gt;Block&lt;/em&gt;: Get stuck waiting.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:f09b8128b2cd6dc70217eeb5f2ae4fb1:7&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Grokking xv6</title>
      <link>http://localhost:1313/unix00/</link>
      <pubDate>Sat, 20 Jun 2015 16:00:25 +0200</pubDate>
      
      <guid>http://localhost:1313/unix00/</guid>
      <description>

&lt;p&gt;This is my first post in a series on grokking xv6, a simple Unix-like teaching
operating-system. &lt;em&gt;To grok something&lt;/em&gt; means to understand it intuitively or
empathetically.&lt;/p&gt;

&lt;p&gt;xv6 is a modern rewrite of Unix V6, the first Unix that was published outside of
Bell Labs, and John Lion&amp;rsquo;s commentary of its source code. It consist of a text
and the source code. In total the source is under 10 000 lines of code, and the
book is under 100 pages. You can find out more at MIT&amp;rsquo;s Operating Systems
Engineering &lt;a href=&#34;http://pdos.csail.mit.edu/6.828/2014/xv6.html&#34;&gt;class website&lt;/a&gt;,
which is where xv6 was written.&lt;/p&gt;

&lt;h2 id=&#34;motivation:e5c1e941bdd2f8c7b7464f7c70353dd0&#34;&gt;Motivation&lt;/h2&gt;

&lt;p&gt;When I quit my last job, I asked the CTO, a programmer whose ability I highly
respect, what he thought were my biggest weaknesses as a programmer. His answer
was clear: systems programming and type systems. What is systems programming?
The short answer is: software that isn&amp;rsquo;t application software.&lt;/p&gt;

&lt;p&gt;On the late Richard Feynman&amp;rsquo;s
&lt;a href=&#34;http://caltech.discoverygarden.ca/islandora/object/ct1%3A483/datastream/JPG/view&#34;&gt;blackboard&lt;/a&gt;
you can read: &lt;em&gt;Know how to solve every problem that has ever been solved&lt;/em&gt; and
&lt;em&gt;What I cannot create I do not understand&lt;/em&gt;.  This is of course just an ambition.
And while I don&amp;rsquo;t share his ambition for being able to solve every problem that
has ever been solved, I think he&amp;rsquo;s spot on when it comes to achieving deep
understanding. Consider this my attempt at grokking systems programming.&lt;/p&gt;

&lt;p&gt;C and UNIX have been around for 30 years and they are likely to be around in
another 30 years. While I don&amp;rsquo;t have much experience writing C, I have a lot of
respect for it as an abstraction. Together with Lisp, it strikes me as cleanest
model of programming that exists (I took that one from &lt;a href=&#34;http://www.paulgraham.com/rootsoflisp.html&#34;&gt;Paul
Graham&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Regardless of what you end up doing as a programmer, it&amp;rsquo;s extremely helpful to
have a grasp of the fundamentals. UNIX and its philosophy have such a huge
influence on programming at large, there&amp;rsquo;s nothing you can do that they don&amp;rsquo;t
touch. Even if you are making a web app, once it reaches a certain size you are
bound to run into issues that have already been studied at length in the world
of operating systems.&lt;/p&gt;

&lt;h2 id=&#34;hypotheses:e5c1e941bdd2f8c7b7464f7c70353dd0&#34;&gt;Hypotheses&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;1. With dedicated study, I&amp;rsquo;ll be able to grok xv6 in about a month.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;To make the concept of grokking more concrete:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;understand every single line in the source code&lt;/li&gt;
&lt;li&gt;teach it or parts of it to someone else&lt;/li&gt;
&lt;li&gt;rewrite or extend parts of the source code&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The first will be more of a qualitative test to apply to myself, I aim to do the
second in these posts, and the third will be done with the help of MIT&amp;rsquo;s 6.828
&lt;a href=&#34;http://pdos.csail.mit.edu/6.828/2014/schedule.html&#34;&gt;homework&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2. After grokking xv6 I&amp;rsquo;ll have a firm grasp of fundamental OS concepts.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This can be tested by:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ability to understand modern operating systems&lt;/li&gt;
&lt;li&gt;contributing a patch to a modern OS like Linux or FreeBSD&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;See this HN &lt;a href=&#34;https://news.ycombinator.com/item?id=4599048&#34;&gt;comment&lt;/a&gt; for why the
second wouldn&amp;rsquo;t be as unreasonable of a goal as it may appear at first.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3. After grokking xv6 I&amp;rsquo;ll have developed working knowledge of C.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This can be tested by understanding and / or contributing to a non-trivial open
source project written in C.&lt;/p&gt;

&lt;h2 id=&#34;methodology:e5c1e941bdd2f8c7b7464f7c70353dd0&#34;&gt;Methodology&lt;/h2&gt;

&lt;p&gt;In future posts I will choose something specific to teach and focus each post on
that. In that sense it can best be seen as one long post, with this being the
introduction. After having finished with xv6, I&amp;rsquo;ll write some sort of
conclusion. In other words, this experiment is a work in progress.&lt;/p&gt;

&lt;p&gt;If you wish to follow along, you can do so on a weekly basis here. You can also
read my daily code journal. The latest entry can be found by typing &lt;code&gt;curl -L
plan.oskarth.com&lt;/code&gt; into your terminal. If you want to see previous entries you
can find them at &lt;code&gt;curl plan.oskarth.com/list&lt;/code&gt;. All the code is available on
&lt;a href=&#34;https://github.com/oskarth/xv6&#34;&gt;Github&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Writing A Lisp Interpreter</title>
      <link>http://localhost:1313/lisp-interpreter/</link>
      <pubDate>Sun, 14 Jun 2015 13:21:00 +0200</pubDate>
      
      <guid>http://localhost:1313/lisp-interpreter/</guid>
      <description>

&lt;p&gt;I&amp;rsquo;ve always really liked Lisp as a programming language, but I&amp;rsquo;ve yet to write
an interpreter for the language. This week I decided to change that.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hypothesis:&lt;/strong&gt; I can write a lisp interpreter in under 500 LOCs and in under a
week.&lt;/p&gt;

&lt;p&gt;Since the beginning of last week I&amp;rsquo;ve been keeping a &lt;a href=&#34;https://twitter.com/oskarth/status/608397165925437441&#34;&gt;code journal&lt;/a&gt;. To give you a
feel for process so far of this project, I&amp;rsquo;m posting some excerpts from it
related to this project.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tuesday&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I&amp;rsquo;m working on my own little Lisp interpreter, based on the one described in SICP. My goal is to get it to a reasonable state by the end of this week, and then we&amp;rsquo;ll see.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Wednesday&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I got stuck in a code mess where I had a bad mental model of what was happening when I was encoding and calling built-in primitive functions. I decided to start over using LISP 1.5 Programmer&amp;rsquo;s Manual and a legal pad.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Friday&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Earlier I had started with the eval and apply functions, and then tried to add the environment and all the other &amp;ldquo;details&amp;rdquo;, such as primitive procedures and their bindings, ad hoc. This meant that I often didn&amp;rsquo;t have working code, and my mental model suffered as a result.&lt;/p&gt;

&lt;p&gt;Today I started from the bottom-up, which is generally a much better way to do Lisp programming, so my confidence in the code and its workings grew. When I found bugs, I knew almost straight away where the problem was.&lt;/p&gt;

&lt;p&gt;I can now evaluate basic lambdas with proper scoping. The biggest problem was to reconcile the lack of mutable cons cells in Racket with the design SICP has for its environment model. I wasted a lot of time using mutable-cons, which infected the rest of my program. Eventually I decided to remove definitions and assignments, until I figured out how to deal with this mismatch. I also haven&amp;rsquo;t implemented conditionals yet.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Saturday&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I saw someone on Github who solved the issue with mutable pairs. Essentially it was the same as what I had done, with the addition of a function that converts all user input lists to mutable lists, along with a convenience macro that allows us to use mcadr, and other nested access functions. This strikes me as a hack that works, but not as the right solution.&lt;/p&gt;

&lt;p&gt;After talking to some helpful people on IRC, especially technomancy of Leiningen and Atreus fame, I got some pointers on how to approach the problem. I decided to keep the local environment immutable, and just create a hash-map for the mutable top-level, for defining functions and such.&lt;/p&gt;

&lt;p&gt;I also gave the lisp interpreter a real name: Sai. It&amp;rsquo;s my little celebration of to the spirit in the machine. I&amp;rsquo;d like to keep working on it more - for example, I&amp;rsquo;d like to implement a macro system and play around with that. We&amp;rsquo;ll see if or
when time permits.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Here are two basic program that demonstrates functions, definitions, conditionals,
scoping, and basic data types.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(((lambda (x) (lambda (y) (+ x y))) 3) 4) ; =&amp;gt; 7

(define (append x y)
  (if (null? x)
    y
    (cons (car x) (append (cdr x) y))))

(append &#39;(a b c) &#39;(d e f)) ; =&amp;gt; &#39;(a b c d e f)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Sai is on Github &lt;a href=&#34;https://github.com/oskarth/sai&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;conclusion-and-future-work:dd9cfdd1a70152eeed1ac2dbb9a57cf1&#34;&gt;Conclusion and future work&lt;/h2&gt;

&lt;p&gt;Yes, it was possible, and it ended up being less than 200 lines of code. It&amp;rsquo;s
very rudimentary and doesn&amp;rsquo;t support a lot, so that number doesn&amp;rsquo;t mean that
much.&lt;/p&gt;

&lt;p&gt;Of course, since I was mostly following the path laid out in SICP it&amp;rsquo;s not that
surprising. But I do know a lot more now than I knew a week ago, and I&amp;rsquo;ve a
feeling this project helped with my intution for how programming languages work.&lt;/p&gt;

&lt;p&gt;There are a few different things I&amp;rsquo;d like to play around with: implementing a
macro system, Clojure-like data structures, minimizing the amount of primitives
in the eval function, writing some real programs in it, writing the interpreter
in a different language, etc.&lt;/p&gt;

&lt;p&gt;There&amp;rsquo;s a lot to do and I&amp;rsquo;ve barely scratched the surface of programming
language design, but so far it&amp;rsquo;s been very fun and rewarding, and I recommend
you to implement your own lisp interpreter!&lt;/p&gt;

&lt;p&gt;&lt;em&gt;P.S. I might change the format of this experimental journal. For example, I
might change the posting frequency to every other week, or write about one
experiment for several weeks in a row. If you have any thoughts on what kind of
format you think would be interesting to read, please let me know. D.S.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Instadoc - quick access to documentation</title>
      <link>http://localhost:1313/instadoc/</link>
      <pubDate>Sun, 07 Jun 2015 18:00:00 +0200</pubDate>
      
      <guid>http://localhost:1313/instadoc/</guid>
      <description>

&lt;p&gt;If you program in multiple languages, you probably don&amp;rsquo;t know every
language&amp;rsquo;s core functions and standard library by heart. Being able to
look up documentation and source code quickly is vital for staying in
the flow. Here&amp;rsquo;s a test: can you look up your language&amp;rsquo;s documentation
in less than 10 seconds?&lt;/p&gt;

&lt;p&gt;In Clojure I&amp;rsquo;ve always found
&lt;a href=&#34;https://clojure.github.io/clojure/clojure.repl-api.html&#34;&gt;clojure.repl&lt;/a&gt;
to be extremely useful in looking up documentation, source code and to
search for functions using &lt;code&gt;apropos&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Of course, you can always use online resources to look up
documentation. While useful, they require you to be online, are
sometimes confusing, and it can sometimes take a while to find things;
it&amp;rsquo;s not uncommon that looking something up online breaks my flow.&lt;/p&gt;

&lt;h2 id=&#34;hypothesis:46ce418605f3a770af379bf3a9c68ef4&#34;&gt;Hypothesis&lt;/h2&gt;

&lt;p&gt;Ten seconds is a somewhat arbitrary limit, but I chose it for a
specific reason: it&amp;rsquo;s widely seen as the limit for
&lt;a href=&#34;http://www.nngroup.com/articles/response-times-3-important-limits/&#34;&gt;keeping a user&amp;rsquo;s attention&lt;/a&gt;. While
that research was done for more passive tasks, I thought it was a good
starting point. For example, if I have to type something really
complicated to get the source code of a function, I&amp;rsquo;m much less likely
to do it. Here&amp;rsquo;s my hypothesis:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;In most languages you can look up documentation and source code in
less than ten seconds, using built-in, offline tools.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Additionally, I was interested in looking up examples and finding
code, i.e. search a.k.a. apropos.&lt;/p&gt;

&lt;p&gt;When I say ten seconds, the important thing isn&amp;rsquo;t the absolute time,
but rather that it takes a very short period of time. For example,
writing &lt;code&gt;man strncpy&lt;/code&gt; in a terminal, or evaluating &lt;code&gt;(apropos &amp;quot;byte&amp;quot;)&lt;/code&gt;
in a Clojure REPL gives you results almost instantly (it still takes
some effort to type though, and there are tools in Clojureland that
gives you documentation of a function as you mouse-over it, which
takes less than 0.1 seconds and is thus perceived as happening
instantaneously).&lt;/p&gt;

&lt;h2 id=&#34;results:46ce418605f3a770af379bf3a9c68ef4&#34;&gt;Results&lt;/h2&gt;

&lt;p&gt;I took a look at a few languages I have used. There are probably
errors in the following table, and I would love to be corrected. I
found no dedicated tools for code examples, instead they are often put
at the end of the documentation string, if there are any at all.&lt;/p&gt;

&lt;p&gt;Here are the preliminary results:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Language&lt;/th&gt;
&lt;th&gt;Shell&lt;/th&gt;
&lt;th&gt;REPL&lt;/th&gt;
&lt;th&gt;Source&lt;/th&gt;
&lt;th&gt;Search&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Python&lt;/td&gt;
&lt;td&gt;&lt;code&gt;pydoc&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;help&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;inspect&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;pydoc&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Clojure&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;&lt;code&gt;clojure.repl&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;clojure.repl&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;clojure.repl&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Scala&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Go&lt;/td&gt;
&lt;td&gt;&lt;code&gt;godoc&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;C&lt;/td&gt;
&lt;td&gt;&lt;code&gt;man&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Perl&lt;/td&gt;
&lt;td&gt;&lt;code&gt;perldoc&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;td&gt;&lt;code&gt;perldoc&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;perldoc&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;I put up a live spreadsheet that you can see and edit
&lt;a href=&#34;http://experiments.oskarth.com/instadoc-live/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;conclusion:46ce418605f3a770af379bf3a9c68ef4&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;It&amp;rsquo;s probably too early to draw any real conclusions from the limited
data, but I was surprised to find out how hard it seems to be to find
source code in Scala, Go and C, and that Scala&amp;rsquo;s offline documentation
is so bad.&lt;/p&gt;

&lt;p&gt;Regardless, I hope this very incomplete list is useful for someone,
and hopefully it can serve as a starting list for a more complete
collection of getting documentation more quickly. I will update this
post as I get more data.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Nand to Tetris 2</title>
      <link>http://localhost:1313/nand-to-tetris-2/</link>
      <pubDate>Fri, 29 May 2015 19:00:00 +0200</pubDate>
      
      <guid>http://localhost:1313/nand-to-tetris-2/</guid>
      <description>

&lt;p&gt;This post is the second part of our Nand to Tetris mental model
diffing series. This week we look at machine language, computer
architecture, and assemblers.&lt;/p&gt;

&lt;p&gt;The format is the same as
&lt;a href=&#34;http://experiments.oskarth.com/nand-to-tetris-1/&#34;&gt;last week&lt;/a&gt; - I&amp;rsquo;ve
written down a collection of assertions and then received answers and
comments from people who know a lot more about these things. Several
people provided feedback this this time and you&amp;rsquo;ll find a list of them
at the end of this post. Let&amp;rsquo;s begin!&lt;/p&gt;

&lt;h2 id=&#34;assertions:05bfb7fd03f3971852673f1015e8ec08&#34;&gt;Assertions&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;1. Assembly language is just mnemonic sugar over binary codes.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This means that if you read assembly you can straightforwardly, albeit
tediously, translate it into binary code. It also means you have “one
assembler” per computer architecture.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;There are certainly &amp;ldquo;high level&amp;rdquo; assembly languages where one
mnemonic has multiple possible valid translations, but in general it&amp;rsquo;s
accurate. It depends on what you mean exactly, for example look at
AT&amp;amp;T vs Intel x86 assembly - they’re quite similar, and can be
translated to each other, but people get really annoyed when they’re
used to one and have to deal with the other, even just reading
it. (And all of this, in turn, is leaving out what defines a computer
architecture - is a system that can be big-Endian or little-Endian one
architecture or two?)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2. Screen, Keyboard et al. are usually accessed through a memory map.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Alternatively, I know we can issue high-level instructions to a GPU
that yields much better performance, such as &amp;ldquo;draw a line from here to
here&amp;rdquo;. I don&amp;rsquo;t know why that is.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;This depends on both the hardware and the OS, but I think that this
is generally not true for &amp;ldquo;slow&amp;rdquo; I/O devices like a keyboard. For
example, in x86/DOS, I believe that you get an
&lt;a href=&#34;http://webpages.charter.net/danrollins/techhelp/0106.HTM&#34;&gt;int 0x09&lt;/a&gt;
for each keypress. With a modern version of Windows and an x64/SMP
system, it somehow uses ACPI and APIC, and I believe it’s valid to
think of that as an abstraction over
&lt;a href=&#34;https://en.wikipedia.org/wiki/Interrupt&#34;&gt;interrupts&lt;/a&gt;. The DOS case is
pretty simple, and the link above explains how you can get access to
keypresses. Modern interrupt I/O is much more complicated, and for
Windows you can read more about it in
&lt;a href=&#34;http://www.amazon.com/Windows-Internals-Part-Developer-Reference/dp/0735648735/&#34;&gt;Russinovich’s Windows Internals book&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Fast I/O devices will just
&lt;a href=&#34;https://en.wikipedia.org/wiki/Direct_memory_access&#34;&gt;DMA&lt;/a&gt; stuff in and
out of memory, though. There are multiple reasons why fast I/O devices
are faster. The first is that they can just directly talk to memory
instead of having to talk to a device, which talks to another device,
which signals the CPU to talk to the I/O device to do work. And that
signal will cause a context switch,
&lt;a href=&#34;http://danluu.com/new-cpu-features/#context-switches-syscalls&#34;&gt;which is pretty expensive&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Another reason is that they can sit on much faster busses. PCIe gen 3
can deliver about 1GB per lane, and it’s not uncommon to see 16+ lane
devices. That’s a lot more than you can get out of USB. Compare that
to USB3, where you get maybe 10Gb/s, i.e., barely more than 1GB/s,
total. And you can do even better than PCIe if you’re on the same bus
that the processor is on, and that’s one reason that AMD and IBM
expose that stuff. I don’t know if you can get a
&lt;a href=&#34;https://en.wikipedia.org/wiki/Intel_QuickPath_Interconnect&#34;&gt;QPI&lt;/a&gt;
license from Intel, but maybe?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Why is the GPU so much faster?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Using a memory map adds memory copy latency and saturates the memory
bandwidth between CPU and GPU.  For example, consider pressing return
to create a new line at the bottom of a page &amp;ndash; you need to scroll
everything on the view up by a line height, then add your new blank
line.  Doing this pixel by pixel is slower than issuing a GPU command
that says &amp;ldquo;copy a rectangle from [(x=0, y=100), (x=width, y=height)]
to [(x=0, y=0), (x=width, y=height-100)], then fill in a background
color area from height-100 to height.&amp;rdquo;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;In short: The GPU is so much faster because there’s no
throughput/latency bottleneck in copying memory across the
motherboard. GPUs are also optimized for parallel processing (such as
performing an operation on a matrix of pixels), and CPUs aren’t.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3. GOTOs and jumps are the only branching statements in Assembly.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;This depends on the assembly language and architecture. For example,
x86 has a &lt;code&gt;loop&lt;/code&gt; instruction. This is not just a macro. It’s possible
some CPUs will implement &lt;code&gt;loop&lt;/code&gt; as a conditional branch, but it’s
literally a hardware instruction. For an interesting example, look up
x86 string instructions. They were designed to be fast, then were a
slow option that stuck around for backwards compatibility, etc.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;What about Dijkstra&amp;rsquo;s &amp;ldquo;GOTO considered harmful?&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Dijkstra wanted to promote another, more structured, way of dealing
with software: procedures with one entry and one exit point. Taken to
its extreme, this leads to hard-to-analyze programs, full of extra
control flags for the one exit point of the function, and much uglier
error-handling code - the Linux kernel extensively uses goto in
functions where there have to be multiple memory allocations, any of
which may fail, and where the subset that were done need to be cleaned
up, for instance. All that said, some level of structured programming
is generally much preferable to most uses of GOTO.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4. The von Neumann bottleneck is still a thing.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Our computer architecture illustrates the
&lt;a href=&#34;http://en.wikipedia.org/wiki/Von_Neumann_architecture#Von_Neumann_bottleneck&#34;&gt;von Neumann bottleneck&lt;/a&gt;,
without explicitly talking about it. Here&amp;rsquo;s a cameo from
&lt;a href=&#34;https://en.wikipedia.org/wiki/John_Backus&#34;&gt;John Backus&lt;/a&gt; which laments
the existance of it:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Surely there must be a less primitive way of making big changes in
the store than by pushing vast numbers of words back and forth through
the von Neumann bottleneck. Not only is this tube a literal bottleneck
for the data traffic of a problem, but, more importantly, it is an
intellectual bottleneck that has kept us tied to word-at-a-time
thinking instead of encouraging us to think in terms of the larger
conceptual units of the task at hand. Thus programming is basically
planning and detailing the enormous traffic of words through the von
Neumann bottleneck, and much of that traffic concerns not significant
data itself, but where to find it.&lt;/em&gt; (from his
&lt;a href=&#34;http://www.thocp.net/biographies/papers/backus_turingaward_lecture.pdf&#34;&gt;Turing Award lecture&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Yes. Higher level languages help conceptually, but not so much in
terms of implementation. Having tools to cut the CPU out of dealing
with things like blatting data from devices to RAM helps a bit. But
fundamentally, CPUs have gotten really fast, memory access is
amazingly slow, disk access slower yet, and caches only partly
help. &lt;a href=&#34;http://stackoverflow.com/questions/4087280/approximate-cost-to-access-various-caches-and-main-memory&#34;&gt;This&lt;/a&gt;
has some numbers that give an idea of the costs.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;5. All symbols in an Assembler resolve to some memory address.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;No, one might denote a numerical constant, for instance. Symbol
resolution is surprisingly deep, and parts happen at runtime - check
out LD_PRELOAD, LD_LIBRARY_PATH, and similar under Linux, for
instance, where even the library to be loaded, much less addresses
within it, can vary every time you launch the program, not just at
compile time. &lt;a href=&#34;http://www.iecc.com/linker/&#34;&gt;Linkers and loaders&lt;/a&gt; if
quite a fun read if you have a few hours to spare.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;conclusion:05bfb7fd03f3971852673f1015e8ec08&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;All the credit goes to these people, and any inaccuracies are due to
this author:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://danluu.com/&#34;&gt;Dan Luu&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://printf.net/&#34;&gt;Chris Ball&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Darius Bacon&lt;/li&gt;
&lt;li&gt;Kat&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Compared to last week, things got a lot more subtle quickly. It&amp;rsquo;s not
that last week was less complicated, but the answers and diff seemed
more straightforward. I suspect this will be increasingly true as we
move up the stack, as things change more quickly the higher up we get.&lt;/p&gt;

&lt;p&gt;A very low-resolution view of how the assertions fared would go
something like this: Ish, No, No, Yes, No. This is good news: it means
we are learning :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Nand to Tetris 1, with Dan Luu</title>
      <link>http://localhost:1313/nand-to-tetris-1/</link>
      <pubDate>Fri, 22 May 2015 22:00:00 +0200</pubDate>
      
      <guid>http://localhost:1313/nand-to-tetris-1/</guid>
      <description>

&lt;p&gt;In the last few weeks I&amp;rsquo;ve been working my way through the excellent
book &lt;em&gt;Elements of Computing Systems - building a modern computer from
first principles&lt;/em&gt; as part of the equally excellent Nand to Tetris
MOOC.&lt;/p&gt;

&lt;p&gt;I started reading the book a few years ago when I attended Recurse
Center, but instead of completing it I ended up
&lt;a href=&#34;http://blog.oskarth.com/writing-a-dsl-in-clojure&#34;&gt;writing a domain specific language&lt;/a&gt;
for the first few chapters. A useful exercise, no doubt, but this time
around I intend to finish the whole book.&lt;/p&gt;

&lt;p&gt;The main reason I want to go through the book is because I want to
have a better sense of how a computer works, and get a rough idea how
one could build one. In a sense its value is proportional to how well
it serves as a mental model for the real world.&lt;/p&gt;

&lt;p&gt;So how does it stack up? This is the first of a multi part series,
starting with the first three chapters of the Elements of Computer
Systems book, on boolean logic, boolean arithmetic, and sequential
logic. I wrote down a collection of assertions that I wanted to diff
with what&amp;rsquo;s out there in the real world. &lt;a href=&#34;http://danluu.com/&#34;&gt;Dan Luu&lt;/a&gt;
was gracious enough to give me some great answers based on his
expertise in the field. His answers are in italics.&lt;/p&gt;

&lt;p&gt;While I highly recommended that you&amp;rsquo;ve taken the equivalent of a Nand
to Tetris course, this is not strictly necessary. With some luck this
series will convince you to embark on a similar project on your own.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s begin.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. Any boolean function can and usually is built from NAND gates.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;While this is conceptually accurate, this usually isn’t done in
 practice. There are multiple reasons for this, but it mostly comes
 down to cost, power, and performance. The performance aspect is that
 you can directly implement functions with transistors more
 efficiently than you can with NAND gates. You can, very loosely,
 think of this as similar to how compilers sometimes inline functions
 and then do optimizations across inlined functions.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;This property, that any boolean function (i.e. any truth table) can be
built using just NAND gates, is called functional completeness, and
the proof is quite neat. Consider a truth table for some function and
some variables. Each row where the function evaluates to true can be
represented by ANDing together the variables, which are represented
either as true or NOT true. We then OR together all rows to get a
complete representation of that function’s truth table. For example,
Xor(a,b) evaluates to true when either a or b is true. We can
represent this as follows: OR(AND(a, NOT(b)) , AND(NOT(a), b)). We can
thus express any boolean function using just AND, NOT and OR. It then
turns out, using
&lt;a href=&#34;https://en.wikipedia.org/wiki/De_Morgan&#39;s_laws&#34;&gt;De Morgan&amp;rsquo;s laws&lt;/a&gt; and
similar logical relationships, that we can express AND, NOT, OR in
terms of NAND.&lt;/p&gt;

&lt;p&gt;Another cool thing Dan taught me is why NAND gates are usually
prefered over NOR gates, despite both of them being functionally
complete. If you are interested in that, you can read more
&lt;a href=&#34;https://electronics.stackexchange.com/questions/110649/why-is-nand-gate-preferred-over-nor-gate-in-industry&#34;&gt;here&lt;/a&gt;. However,
we did manage to get to the moon in the 60s using just
&lt;a href=&#34;https://en.wikipedia.org/wiki/Apollo_Guidance_Computer#Design&#34;&gt;NOR gates&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2. Logical functions are built up from more elementary ones.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Again, this is conceptually correct, but for performance reasons
 people sometimes build logical functions directly from
 transistors. For much more detail on this,
 &lt;a href=&#34;http://www.amazon.com/CMOS-VLSI-Design-Circuits-Perspective/dp/0321547748&#34;&gt;Weste &amp;amp; Harris&lt;/a&gt;
 is great. For a quick explanation, see
 &lt;a href=&#34;http://www.cerc.utexas.edu/~jaa/vlsi/lectures/3-1.pdf&#34;&gt;this&lt;/a&gt;. That
 explanation isn&amp;rsquo;t self contained. Some things you want to know are
 that the funny symbol near the bottom of those diagrams is ground
 (0), the funny line/symbol at the top is the on voltage (1). Then you
 have the transistors. If there&amp;rsquo;s a bubble on the gate (input), that&amp;rsquo;s
 a PMOS transistor. It turns on (conducts) when the input is 0, and
 it&amp;rsquo;s good at passing &amp;ldquo;1&amp;rdquo;s. Otherwise, it&amp;rsquo;s an NMOS, and has the
 opposite properties.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Similar to the answer above, the interface is correct but the implementation is naive to the point of being misleading.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3. Integers are represented by two&amp;rsquo;s complement.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Yes, 1&amp;rsquo;s complement is rarely used, although there are some applications where it’s superior. You might also be interested in logarithmic and residue number systems, which make some operations easier (faster) at the cost of making other operations slower. For more on that, &lt;a href=&#34;http://www.amazon.com/Computer-Arithmetic-Algorithms-Second-Edition/dp/1568811608&#34;&gt;Koren&lt;/a&gt; has a really nice text.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Also, in contrast to the address you build in nand2tetris, adders are
commonly built using some kind of parallel prefix tree to reduce the
delay (i.e., increase the
performance). &lt;a href=&#34;http://en.wikipedia.org/wiki/Carry-lookahead_adder&#34;&gt;Carry-lookahead adders&lt;/a&gt;
are probably the simplest form of this, but they’re not usually the
fastest thing you can do. The Weste&amp;amp;Harris book mentioned above has a
lot more information on different types of prefix trees.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;This one was funny, as I think of a carry-look-ahead as a neat
optimization, whereas in the real world it’s too slow to use by
itself.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4. When adding integers in a real-world Adder, overflows are ignored.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;It depends! It’s not an error, but there’s often an output from the
 ALU that signals an overflow.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;5. Our ALU is essentially the same as a real one.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;(Our ALU has two 16-bit inputs, six control bits, two output flags,
and one 16-bit output).&lt;/p&gt;

&lt;p&gt;&lt;em&gt;It’s missing
 &lt;a href=&#34;http://en.wikipedia.org/wiki/Pipeline_(computing)&#34;&gt;pipelining&lt;/a&gt;,
 &lt;a href=&#34;http://en.wikipedia.org/wiki/Operand_forwarding&#34;&gt;forwarding&lt;/a&gt;, and
 other performance optimizations, but, fundamentally, it does the same
 stuff as a “real” ALU. Real is in quotes since it’s no less real than
 any other ALU, although “real” ALUs usually implement many more
 functions, have more control bits, etc. :-). Also, some “real” ALU
 operations can also take several clock cycles, unlike the one in your
 design.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;6. There&amp;rsquo;s one master clock that keeps track of computer time.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;This is correct for designs that are made to be simple. However, in
 “real” designs there is often more than one clock for a multitude of
 reasons, such as dealing with I/O devices that run at different
 speeds. For more on how to deal with that, see
 &lt;a href=&#34;http://www.sunburst-design.com/papers/CummingsSNUG2008Boston_CDC.pdf&#34;&gt;this&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;I would say this makes my mental model incorrect, in that I would
expect one clock cycle to be the unit that everything in hardware
uses, but at second thought I see why that wouldn’t make sense with
I/O-bound hardware parts.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;7. Our Register, RAM and Program Counter are essentially realistic.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;(In addition to 16-bit input and outputs, we have the following: Our
Register has a load bit, our RAM a load bit and an n-bit address, and
our Program Counter has a load, inc, and reset bit).&lt;/p&gt;

&lt;p&gt;&lt;em&gt;This is true conceptually/logically. However, in “real” systems
 register files are often custom circuits built at the transistor
 level, and RAMs are also custom. On chip RAMs are usually SRAMs,
 which are built out of transistors like other chip logic (although
 they typically have an analog component to them, unlike the logic
 you’ve built). Off chip DRAM is a totally different beast. There’s
 also normally multiple read/write ports, as opposed to just one
 combined read/write address.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;This also makes sense, but the shared memory bit sounds scary. Yet
another rabbit hole to go into, for a rainy day.&lt;/p&gt;

&lt;h2 id=&#34;conclusion:27691ee23bcc4ace73e6c7539d1a2f9c&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;In general, most of my assertions were right on an interface level,
but wrong on an implementation level. Is this a good mental model? I
think so. Unless you are building a real computer it’s good enough,
conceptually. You could also, theoretically at least, build a computer
using the tools given to you in Nand to Tetris that would be similar
to an Intel machine from the early 80s, which isn’t that bad.&lt;/p&gt;

&lt;p&gt;In the next part we’ll move higher up the stack, looking at machine
language, computer architecture and an assembler.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to Follow pmarca on Twitter</title>
      <link>http://localhost:1313/how-to-follow-pmarca/</link>
      <pubDate>Fri, 15 May 2015 20:00:00 +0200</pubDate>
      
      <guid>http://localhost:1313/how-to-follow-pmarca/</guid>
      <description>

&lt;p&gt;It started with a question: how do you follow @pmarca on Twitter?
@pmarca is Marc Andreessen, investor and cofounder of
Netscape. Averaging 100 tweets a day, he is hard to keep up with.&lt;/p&gt;

&lt;p&gt;When I asked this question to a group of people I got essentially two
types of answers: (a) don&amp;rsquo;t try to keep up (b) make judicious use of
lists. While useful, I don&amp;rsquo;t think these suggestion hit the core of
the problem:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Twitter Attention Inequality&lt;/strong&gt;: A person tweeting 100 times a day
gets 100 times more exposure than someone tweeting once a day, even
though you care equally about what they have to say.&lt;/p&gt;

&lt;p&gt;When I first tried to solve this problem a few months ago, I wrote a
bunch of code that tried to solve the problem in a general way,
essentially making a Twitter app that displays anyone&amp;rsquo;s timeline
filtered through a some kind of relevance score. The details don&amp;rsquo;t
matter - the gist is that I wasted a bunch of time dealing with
Twitter API restrictions (OAuth 1, rate limits, broken libraries,
unable to use certain APIs, more rate limits, etc) rather than testing
my assumptions. I attacked the problem twice, and ended up abandoning
both approaches.&lt;/p&gt;

&lt;p&gt;Yesterday I started thinking about the problem again, and realized
there was a bunch of assumptions I could test without writing a single
line of code.&lt;/p&gt;

&lt;h2 id=&#34;hypotheses:4215a884d8a0dd0e6794f6fcc8464cd6&#34;&gt;Hypotheses&lt;/h2&gt;

&lt;p&gt;First some observations: (a) I ignore most tweets and (b) unlike
email, there are no can&amp;rsquo;t-miss tweets in a timeline.&lt;/p&gt;

&lt;p&gt;Here are some assumptions I wanted to test:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Some people tweet 10x more than average.&lt;/li&gt;
&lt;li&gt;Some people tweet more relevant things than others.&lt;/li&gt;
&lt;li&gt;Removing heavy tweeters will increase timeline relevance.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;experiment:4215a884d8a0dd0e6794f6fcc8464cd6&#34;&gt;Experiment&lt;/h2&gt;

&lt;p&gt;I looked at the last 200 tweets that came up in my timeline, which
roughly corresponds to a 20 hour window. For each tweet I put them in
one of three categories:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Ignore&lt;/li&gt;
&lt;li&gt;Engage (click, reply, think briefly about)&lt;/li&gt;
&lt;li&gt;Recommend (favourite, retweet, or write down with other means)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This was a snap decision, and my measured engagement rate was probably
higher than my actual one, since I don&amp;rsquo;t normally look carefully at
every tweet.&lt;/p&gt;

&lt;h2 id=&#34;data:4215a884d8a0dd0e6794f6fcc8464cd6&#34;&gt;Data&lt;/h2&gt;

&lt;p&gt;Out of the 200 tweets, I engaged with 20% (35) of them. Less than 5%
(1.5%) were marked as recommended. The number of 3s were so negliable,
just two in that time period, that I decided to bake it into the
&amp;ldquo;Engage&amp;rdquo; category. Thus, 80% of tweets were simply noise.&lt;/p&gt;

&lt;p&gt;Looking at @pmarca&amp;rsquo;s tweets during the same 20 hour period, I found
that he tweeted 30-35 times. I follow around 150 people, which makes
@pmarca 30x more prolific of a tweeter than the average person I
follow.&lt;/p&gt;

&lt;p&gt;However, I noticed something surprising. The engagement rate for
@pmarca&amp;rsquo;s tweets was 20%, just as it was with my normal timeline! This
invalidated my third assumption.&lt;/p&gt;

&lt;p&gt;Is it possible to increase the relevance of @pmarca&amp;rsquo;s tweets in a
straighforward way? I tried filtering out his retweets, as well as
only looking at the ones with a favourite count of 100 or
more. Neither resulted in a higher engagement ratio (sample size 10),
and both were implicit assumptions that I had in my initial
prototypes.&lt;/p&gt;

&lt;p&gt;I also looked at three people I knew were high-quality tweeters. My
engagement for their tweets was over 50% (sample size 10), which
suggests there is such a thing as more relevant tweeters [1].&lt;/p&gt;

&lt;h2 id=&#34;a-smaller-version:4215a884d8a0dd0e6794f6fcc8464cd6&#34;&gt;A smaller version&lt;/h2&gt;

&lt;p&gt;If my engagement ratio with @pmarca&amp;rsquo;s tweets is the same as my normal
timeline, why don&amp;rsquo;t I follow him? One way to think about it is in
terms of attentions. If I have 100 attentions, where one attention is
one tweet, then I don&amp;rsquo;t want to spend a large portion of them on one
person. Outside of its conversation-like nature, one of the main
benefits of Twitter is that it allows for a plurality of views.&lt;/p&gt;

&lt;p&gt;After having freed my mind from thinking I have to predict the quality
of a tweet or tweeter, I arrived at an obvious and simple solution:
just remove 90% randomly of his tweets, to reduce the volume! So I
created a small Twitter bot that does exactly this, in just 50 lines
of code of Clojure.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(ns pmarca-chen.core
  (:require [clojure.set :as set]
            [twitter.oauth :as oauth]
            [twitter.api.restful :as api]))

(def old-tweets (atom #{}))

(def my-creds (oauth/make-oauth-creds
               (System/getenv &amp;quot;PMARCACHEN_CONSUMER_KEY&amp;quot;)
               (System/getenv &amp;quot;PMARCACHEN_CONSUMER_SEC&amp;quot;)
               (System/getenv &amp;quot;PMARCACHEN_ACCESS_TOKEN&amp;quot;)
               (System/getenv &amp;quot;PMARCACHEN_ACCESS_TOKEN_SEC&amp;quot;)))

(defn timeline []
  (api/statuses-home-timeline :oauth-creds my-creds))

(defn fetch-tweets []
  (set (map :id (:body (timeline)))))

(defn retweet! [tweet]
  (do (api/statuses-retweet-id :oauth-creds my-creds
                               :params {:id tweet})
      (prn &amp;quot;Tweeted &amp;quot; tweet)))

(defn maybe-retweet!
  &amp;quot;Retweet a tweet 10% of the time.&amp;quot;
  [tweet]
  (if (= (rand-int 10) 9)
    (retweet! tweet)
    (prn (str &amp;quot;Discarded tweet &amp;quot; tweet))))

(defn fetch-and-retweet!
  &amp;quot;Fetches tweets, retweets some, and calculates new tweets, and maybe
  retweets them. Adds new tweets to old tweets set.&amp;quot;
  []
  (let [all-tweets (fetch-tweets)
        new-tweets (set/difference all-tweets @old-tweets)]
    (do (println (str &amp;quot;Found &amp;quot; (count new-tweets) &amp;quot; new tweets.&amp;quot;))
        (dorun (map maybe-retweet! new-tweets))
        (swap! old-tweets set/union new-tweets))))

(defn periodically! [f ms]
  (future (while true (do (Thread/sleep ms) (f)))))

(comment
  (def pmarca-chen (periodically! fetch-and-retweet! (* 1000 60 5)))
  (future-cancel pmarca-chen)
  )
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This checks for the latest tweets every five minutes, diffs the
fetched tweets with tweets that have been seen already to figure out
the new tweets, and retweets a new tweet with a probablity of 10%.&lt;/p&gt;

&lt;p&gt;You can find the source code
&lt;a href=&#34;https://github.com/oskarth/pmarca-chen&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;conclusion:4215a884d8a0dd0e6794f6fcc8464cd6&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;You can follow @pmarca_chen on Twitter
&lt;a href=&#34;https://twitter.com/pmarca_chen&#34;&gt;here&lt;/a&gt;. I hope people find it useful,
and if you create a bot on your own, please let me know and I&amp;rsquo;ll add
it here.&lt;/p&gt;

&lt;p&gt;I would like to end this article with a quote by Herbert Simon:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;A wealth of information creates a poverty of attention&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Ever since I first read that quote a few years, it stuck with me. In a
world where information is abundant, we should fight for our
attention, and come up with new ways of preserving and enriching it.&lt;/p&gt;

&lt;h2 id=&#34;notes:4215a884d8a0dd0e6794f6fcc8464cd6&#34;&gt;Notes&lt;/h2&gt;

&lt;p&gt;[1] This is outside the scope of this article, but one interesting
idea is to use your own favourite count per user as a proxy for how
relevant a person is to you, and then change your timeline
accordingly.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Law Of The Instrument</title>
      <link>http://localhost:1313/law-of-the-instrument/</link>
      <pubDate>Fri, 08 May 2015 16:00:00 +0200</pubDate>
      
      <guid>http://localhost:1313/law-of-the-instrument/</guid>
      <description>

&lt;p&gt;It&amp;rsquo;s tempting to solve the problem you already know how to solve, as
opposed to the problem that matters. This is true even if you are
aware of it.&lt;/p&gt;

&lt;p&gt;This March, I introduced Unfolds in a
&lt;a href=&#34;http://blog.oskarth.com/unfolds-a-jungle-of-ideas-prototype&#34;&gt;blog post&lt;/a&gt;. Seen
as an experiment, Unfolds was a failure. It&amp;rsquo;s on the order of 500
lines of Clojure/Clojurescript code, and despite being my main hacking
project for about a month, it failed to test an actual hypothesis.&lt;/p&gt;

&lt;p&gt;What I set out to do with Unfolds was to get to the gist of an idea in
a few hundred words. This is mostly a problem of writing these gists
clearly and concisely. Without that you have nothing. I was well aware
of this, but yet I approached the problem by spending my time writing
a tool for creating and browsing these gists. What went wrong? We can
get a clue by listening to the words of Abraham Kaplan:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I call it the law of the instrument, and it may be formulated as
follows: Give a small boy a hammer, and he will find that everything
he encounters needs pounding.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;My hammer was programming, and I was pounding away at a tool that
served a subordinate purpose to gists that don&amp;rsquo;t even exist yet.&lt;/p&gt;

&lt;p&gt;The real problem here is so difficult, and I hadn&amp;rsquo;t sufficiently
deconstructured and simplified it, that I ended up trying to solve a
different problem. It doesn&amp;rsquo;t matter if what you are building is
clever if it doesn&amp;rsquo;t solve a real problem. An hypothesis that can
reasonably be falsified would function as a compass, and keep the
pursuit honest.&lt;/p&gt;

&lt;p&gt;Would making a tool necessarily be a bad idea? No, but that would be a
different direction and a different hypothesis. If you are building a
house with just a hammer, you&amp;rsquo;ll have a bad time cleaning windows.&lt;/p&gt;

&lt;h2 id=&#34;what-would-a-real-hypothesis-look-like:6b88f7334be4fa2dbac03e6a172d8291&#34;&gt;What would a real hypothesis look like?&lt;/h2&gt;

&lt;p&gt;The idea behind Unfolds is still potent, and there are many questions
and hypotheses hiding in it. Here are a few sketches of assertions
that can be tested.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;You can communicate the gist of an idea in less than 200 words. By
gist we mean that reading these words will be enough for most
research purposes.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The first 200 words of a Wikipedia article do not satisfy the
metric in 1.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;This author can explain ten concepts in under 200 words. This is
only true for concepts that are familiar to him.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Images and illustrations are vital in a few select domains, but not
needed in the majority of explanations. Specifically, there&amp;rsquo;s a
trade-off in time investment, and it&amp;rsquo;s usually not worth it.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;There exist heuristics which make a short explanation particularly
good or particularly bad. These can be discovered. It&amp;rsquo;s possible to
build tools that encourage good explanations.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I&amp;rsquo;m sure there are many more, but these are things on the top of my
head that&amp;rsquo;d be interesting to investigate. Some assertions are easier
to test than others, and I&amp;rsquo;ll probably revisit the matter soon.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Watsi Experiment</title>
      <link>http://localhost:1313/watsi-experiment/</link>
      <pubDate>Fri, 01 May 2015 18:00:00 +0200</pubDate>
      
      <guid>http://localhost:1313/watsi-experiment/</guid>
      <description>

&lt;p&gt;Along with Wikipedia, Watsi is probably one of the best uses of the
Internet I&amp;rsquo;ve seen.&lt;/p&gt;

&lt;p&gt;Disclaimer: I have no association with Watsi, except as a user.&lt;/p&gt;

&lt;p&gt;Watsi specialize in low-cost, high-impact healthcare funding. 100% of
donation money goes to a specific patient of your choice, and they are
ridiculously transparent with their finances (there&amp;rsquo;s a google doc
linked from their website containing all their operations and
financials, including screenshots of bank transfers for each
operation). In short, it&amp;rsquo;s hard to imagine a better way to fund
healthcare around the world.&lt;/p&gt;

&lt;p&gt;Last Christmas, I decided to conduct an experiment. I wanted to give
people an opportunity to use Watsi, but instead of giving a large
amount to a few people, or a medium amount to some people, I decided
to give a small amount to many people.&lt;/p&gt;

&lt;h2 id=&#34;hypothesis:2406d8910f03d4cf56e52ea4977a7227&#34;&gt;Hypothesis&lt;/h2&gt;

&lt;p&gt;I did not make a clear hypothesis back then. I was generally curious
about how many people would give Watsi a try, and how many of those
would find it compelling enough to use again. As one person put it,&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;My inner engineer can&amp;rsquo;t help but appreciate that it&amp;rsquo;s likely to
amplify your original donation by roping in some more people too!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This was my intution too.&lt;/p&gt;

&lt;h2 id=&#34;experiment:2406d8910f03d4cf56e52ea4977a7227&#34;&gt;Experiment&lt;/h2&gt;

&lt;p&gt;Around Christmas time, 16 friends, family and acquaintances got a
small dollar dollar gift card ($5 for most, and $20 for family), along
with an email explaining Watsi and that this was part of an
experiment.&lt;/p&gt;

&lt;p&gt;This was not completely thought out. I had opted people into something
without their permission, and several things were unclear (what is the
experiment exactly? what if I don&amp;rsquo;t want to participate?). After some
feedback I sent a second email to clarify that if they didn&amp;rsquo;t use
their gift certificate within three months, the money would go to
Watsi&amp;rsquo;s Universal Fund.&lt;/p&gt;

&lt;p&gt;Three months later, I sent a second email asking people to fill out a
short anonymous 30 second survey. I got a response rate of &lt;sup&gt;11&lt;/sup&gt;&amp;frasl;&lt;sub&gt;16&lt;/sub&gt;. The
questions I asked were the following:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Had you used Watsi before?&lt;/li&gt;
&lt;li&gt;Did you use your gift card?&lt;/li&gt;
&lt;li&gt;On a scale of 1-10 (10 being certain), how likely is it that you
will donate to Watsi again within the coming year?&lt;/li&gt;
&lt;li&gt;Comments/suggestions/critiques (optional)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The responses were as follows. Only 1 person had heard of Watsi
before, 2 people did not use the gift certificate, and the answers to
the third question was: 2-3-3-4-4-6-6-6-7-8-10.&lt;/p&gt;

&lt;p&gt;That only 1 person had heard of Watsi before came as a surprise to me,
and indicates that Watsi is still very small - there&amp;rsquo;s already a
sample bias in the people I chose, as a lot of them are involved in
tech and the startup world.&lt;/p&gt;

&lt;p&gt;Assuming that those who didn&amp;rsquo;t respond to the survey didn&amp;rsquo;t use it,
implies that more than half used their certificate, which is still
pretty good. There were however some problems. One person tried to use
the gift card two or three times, but wasn&amp;rsquo;t able to claim it without
being logged in. Setting up an account did not help the matter
either. This is unfortunate and seems to be a, hopefully temporary,
bug in their system.&lt;/p&gt;

&lt;p&gt;The third question is a trick I learned from my marketing class many
years ago. The idea is that in such questions, only 9 and 10
constitutes a real yes. If we are being generous, we could call a 7 or
8 a maybe, but the rest are best treated as a no. This means we have 1
yes and 2 no, out of 16 people.&lt;/p&gt;

&lt;p&gt;This last result was surprising to me - I would&amp;rsquo;ve assumed this number
would be higher. I&amp;rsquo;ll talk more about this in the next section.&lt;/p&gt;

&lt;p&gt;Here are some other comments that people made.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I donated in my mom&amp;rsquo;s name&lt;/p&gt;
&lt;/blockquote&gt;

&lt;!-- --&gt;

&lt;blockquote&gt;
&lt;p&gt;Tried to set up my own regular donation but I was not allowed to
give a lump sum and too much was lost in currency exchange when
transfers were made monthly. I contacted them for alternatives such
as pay pal but no joy.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;!-- --&gt;

&lt;blockquote&gt;
&lt;p&gt;I&amp;rsquo;m impressed by the follow up with information sent to me about the
receiver of my donation.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;!-- --&gt;

&lt;blockquote&gt;
&lt;p&gt;Not sure I&amp;rsquo;d do it this year &amp;ndash; I think it would be more successful
if the campaign was more connected to something that meant to
me. Like educating inner city kids etc.&lt;/p&gt;

&lt;p&gt;Yeah &amp;ndash; mostly I&amp;rsquo;m just super disconnected from it.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;!-- --&gt;

&lt;blockquote&gt;
&lt;p&gt;I&amp;rsquo;ve done a lot with Kiva, and honestly I&amp;rsquo;m more likely to continue
with that.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;conclusion:2406d8910f03d4cf56e52ea4977a7227&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;This was a successful experiment in that we could test the hypothesis,
even if it was ill-specified. It turns out that people are quite
willing to use a gift certificate, but not as interested in using
Watsi again.&lt;/p&gt;

&lt;p&gt;Given my own high opinion of Watsi, and
&lt;a href=&#34;https://www.changemakers.com/sites/default/files/styles/project_slider/public/growth-graph.png&#34;&gt;their&lt;/a&gt;
&lt;a href=&#34;https://pbs.twimg.com/media/B-QO__bCcAADarb.png&#34;&gt;amazing&lt;/a&gt;
&lt;a href=&#34;https://chartio.com/hmedia/images/blog/2015/03/watsi-data/universal-fund-donations.png&#34;&gt;growth&lt;/a&gt;,
which indicates that they are doing something that people really want,
what went wrong?&lt;/p&gt;

&lt;p&gt;The biggest error source is the way the experiment was set up. There
was a lot of unclear and bad communication on my part, and there was
absolutely zero intent among the people surveyed. This was something I
didn&amp;rsquo;t expect, but it makes a lot of sense. People have different
priorities, are at various stages in their lives, and have a limited
amount of attention. Consider this example: people want cars. It&amp;rsquo;s a
huge industry, people need to get from point A to B. But if you were
to semi-randomly ask people if they want to buy a car from a certain
brand within the next year, most people would say no. Even adjusting
for the different magnitude in purchase decision, that alone is enough
to explain how few people would use it again.&lt;/p&gt;

&lt;p&gt;In fact, despite my initial disappointment, that I got ~10 more people
to know about the existence of Watsi, and that 1 out of 16 will try
Watsi again (a number that would be 2 if they fixed their European
payment options), should be seen as a success, albeit a small one.&lt;/p&gt;

&lt;h2 id=&#34;future-work:2406d8910f03d4cf56e52ea4977a7227&#34;&gt;Future work&lt;/h2&gt;

&lt;p&gt;I see two interesting directions. One is to set up a better experiment
with a bigger sample, and make it opt-in, as opposed to opt-out like
my experiment was. The other is to explore the concept of intent. For
example, what would happen if whenever someone expresses intent of
helping people with healthcare, or talks about wanting to help people
in poor areas, they would get invited to try Watsi for $5? Of course
we have to be careful getting too spammy, but the fact that (a) 100%
goes to the person and (b) it&amp;rsquo;s real money, would mean that the risk
of that would be almost negligible.&lt;/p&gt;

&lt;p&gt;There are many opportunities that open up with the Internet, and Watsi
is a great model for charity in the 21st century.&lt;/p&gt;

&lt;p&gt;If you want to fund healthcare for people all around the world, go to
&lt;a href=&#34;https://watsi.org/&#34;&gt;watsi.org&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>